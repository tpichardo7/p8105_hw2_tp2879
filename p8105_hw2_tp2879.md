P8105 Homework 2
================

# Problem 1

## Reading and Cleaning the NYC Transit data

``` r
nyc_transit_df =  
  read_csv(file = "./hw2_data/nyc_transit.csv",
    col_types = cols(
      Route8 = col_character(), 
      Route9 = col_character(), 
      Route10 = col_character(), 
      Route11 = col_character())) |>
  janitor::clean_names() |>
  pivot_longer(
      cols = route1:route11,
      names_to = "route")
```

``` r
nyc_transit_df |>
  select(
    line, 
    station_location,
    station_name, 
    station_latitude, 
    station_longitude, 
    route, 
    entry, 
    vending, 
    entrance_type, 
    ada
  ) |>
  mutate(entry = ifelse(entry == "YES", TRUE, FALSE))
```

    ## # A tibble: 20,548 × 10
    ##    line   station_location station_name station_latitude station_longitude route
    ##    <chr>  <chr>            <chr>                   <dbl>             <dbl> <chr>
    ##  1 4 Ave… (40.660397, -73… 25th St                  40.7             -74.0 rout…
    ##  2 4 Ave… (40.660397, -73… 25th St                  40.7             -74.0 rout…
    ##  3 4 Ave… (40.660397, -73… 25th St                  40.7             -74.0 rout…
    ##  4 4 Ave… (40.660397, -73… 25th St                  40.7             -74.0 rout…
    ##  5 4 Ave… (40.660397, -73… 25th St                  40.7             -74.0 rout…
    ##  6 4 Ave… (40.660397, -73… 25th St                  40.7             -74.0 rout…
    ##  7 4 Ave… (40.660397, -73… 25th St                  40.7             -74.0 rout…
    ##  8 4 Ave… (40.660397, -73… 25th St                  40.7             -74.0 rout…
    ##  9 4 Ave… (40.660397, -73… 25th St                  40.7             -74.0 rout…
    ## 10 4 Ave… (40.660397, -73… 25th St                  40.7             -74.0 rout…
    ## # ℹ 20,538 more rows
    ## # ℹ 4 more variables: entry <lgl>, vending <chr>, entrance_type <chr>,
    ## #   ada <lgl>

### Discussion

The `nyc_transit_df` dataset contails detailed information about subway
stations in New York City, including variables such as `station_name`,
`line`, `ada`, and `entrance_type`. To prepare the dataset for analysis,
I performed data cleaning steps such as converting the entry variable
from a character to a logical variable. After the cleaning process, the
data is considered tidy, as each variable is represented in its own
column.

## Number of Distinct Stations

``` r
distinct_stations = nyc_transit_df |>
  distinct(station_name, line) |>
  nrow()
```

There are 465 distinct stations.

## Number of ADA Compliant Stations

``` r
ada_compliant_stations = nyc_transit_df |>
  filter(ada == TRUE) |>
  nrow()
```

There are 5148 ADA compliant stations.

## Proportion of Entrances Without Vending that Allow Entry

``` r
total_entrances = nyc_transit_df |>
  filter(vending == "NO") |>
  nrow()

entrances_with_entry = nyc_transit_df |>
  filter(vending == "NO", entry == TRUE) |>
  nrow()

proportion = entrances_with_entry / total_entrances
```

The proportion of station entrances/exits without vending allowing
entrance is 0.

``` r
a_train = 
  nyc_transit_df |> 
    filter(value == "A")

a_distinct = a_train |>
  distinct(station_name) |>
  nrow()

a_compliant = a_train |>
  filter(ada == TRUE) |>
  nrow()
```

There are 56 distinct stations that serve the A train.

There are 107 ADA compliant stations that serve the A train.

# Problem 2

## Reading and Cleaning the Mr.Trash Wheel sheet

``` r
trash_df = read_xlsx("./hw2_data/trash.xlsx")
```

    ## New names:
    ## • `` -> `...15`
    ## • `` -> `...16`

``` r
trash_df = janitor::clean_names(trash_df)
```

``` r
mr_trash = 
  read_xlsx("./hw2_data/trash.xlsx",
    sheet = "Mr. Trash Wheel",
    skip = 1, 
    col_names = TRUE) |> 
  janitor::clean_names() |> 
  mutate(sports_balls = as.integer(sports_balls)) 
```

    ## New names:
    ## • `` -> `...15`
    ## • `` -> `...16`

## Reading and Cleaning the Professor Trash Wheel sheet

``` r
prof_trash = trash_df = 
  read_xlsx("./hw2_data/trash.xlsx",
    sheet = "Professor Trash Wheel",
    skip = 1, 
    col_names = TRUE) |> 
  janitor::clean_names() 
```

## Reading and Cleaning the Gwynnda Trash Wheel sheet

``` r
g_trash = trash_df = 
  read_xlsx("./hw2_data/trash.xlsx",
    sheet = "Gwynnda Trash Wheel",
    skip = 1, 
    col_names = TRUE) |> 
  janitor::clean_names() 
```

## Combining the Trash Wheel sheets

``` r
major_trash_df = 
  mr_trash |>
  full_join(prof_trash, by = c("dumpster", "month", "weight_tons")) |>
  full_join(g_trash, by = c("dumpster", "month", "weight_tons"))
```

### Discussion

The combined `major_trash_df` dataset is comprised of the Mr. Trash
Wheel sheet (`mr_trash`), the Professor Trash Wheel sheet
(`prof_trash`), and the Gwynnda Trash Wheel sheet (`g_trash`). To
prepare the dataset for analysis, I performed several data cleaning
steps, including filtering out rows that do not include
dumpster-specific data, ensuring that the variable names are consistent,
and rounding the values in the `sports_balls` column to the nearest
integer and converting the result to an integer variable. After the
cleaning process, the data is relatively tidy, as each varibale is
stored in its own column, and each observational corresponds to a unique
row.

## Total Weight of Trash Collected by Professor Trash Wheel

``` r
total_weight = prof_trash |> 
  summarize(total_weight = sum(weight_tons, na.rm = TRUE))
```

The total weight of trash collected by Professor Trash Wheel is 488.

## Total Number of Cigarette Butts Collected by Gwynnda in June of 2022

``` r
total_cigarette = g_trash |> 
  filter(
    month == "June",
    year == 2022) |> 
  summarize(total_cigarette = sum(cigarette_butts, na.rm = TRUE)) 
```

The total number of cigarette butts collected by Gwynnda in June of 2022
is 1.812^{4}.

# Problem 3

## Reading and Cleaning the Data of Individual Bakers, Their Bakes, and Their Performance

``` r
bakers_df = 
  read_csv(file = "./hw2_data/bakers.csv", na = c("NA", ".", "")) |>
  janitor::clean_names() |>
  filter(!is.na(baker_name)) |>
  separate(baker_name, into = c("first_name", "last_name"), sep = " ") 
```

    ## Rows: 120 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (3): Baker Name, Baker Occupation, Hometown
    ## dbl (2): Series, Baker Age
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
bakes_df = 
  read_csv(file = "./hw2_data/bakes.csv", na = c("NA", ".", "")) |> 
  janitor::clean_names() |>
  filter(!is.na(baker)) |>
  rename(first_name = baker) 
```

    ## Rows: 548 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (3): Baker, Signature Bake, Show Stopper
    ## dbl (2): Series, Episode
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
results_df = 
  read_csv(file = "./hw2_data/results.csv", na = c("NA", ".", ""), skip = 2) |> 
  janitor::clean_names() |>
  filter(!is.na(baker)) |>
  rename(first_name = baker) 
```

    ## Rows: 1136 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (2): baker, result
    ## dbl (3): series, episode, technical
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

## Checking for Completeness and Correctness

``` r
missing_bakers = anti_join(bakes_df, bakers_df, by = "first_name")
missing_results = anti_join(results_df, bakers_df, by = "first_name")
```

## Merging the Datasets

``` r
gbb_df = 
  bakers_df |>
  full_join(bakes_df, by = c("series", "first_name")) |> 
  full_join(results_df, by = c("series","episode", "first_name")) |> 
  arrange(first_name, series, episode) |> 
  relocate(result, series, episode) |> 
  drop_na(result)
```

## Organizing the Combined Dataset

``` r
gbb_df = gbb_df |>
  select(first_name, everything())
```

## Exporting the Final Dataset

``` r
write_csv(gbb_df, "./hw2_data/gbb_final_dataset.csv")
```

## Star Bakers and Winners - Season 5 through Season 10

``` r
star_bakers_df = 
  gbb_df |>
  filter(series >= 5, series <= 10) |>
  filter(result %in% c("STAR BAKER", "WINNER"))|> 
  relocate(first_name, last_name)
```

The final dataset, `gbb_df`, is a comprehensive and well-structured
composition of individual bakers’ performances across various seasons
and episodes of the Great British Bake Off. Each row represents a unique
entry for a baker, containing key information such as their first and
last names`first_name` and `last_name`, `series`, `episode`, and
`result` such as Star Baker or Winner. The dataset is free from missing
values in crucial areas, ensuring high quality and consistency.

``` r
bakers_table = 
  star_bakers_df |> 
  select(
    season = series,
    episode = episode,
    star_baker = first_name) |>
  mutate(result = ifelse(star_baker == "Winner", "Winner", "Star Baker")) |> 
  arrange(season, episode)

bakers_table = kable(bakers_table, 
                    caption = "Star Baker or Winner of Each Episode (Seasons 5-10)",
                    format = "markdown",
                    colnames = c("First Name", "Last Name", "Result", "Series", "Episode"))
```

There were a few predictable winners such as Candice Brown of Season 7
who was awarded Star Baker three times before ultimately winning the
Great British Bake Off. There were also a few suprising winners such as
David from Season 10 who won the Great British Bake Off without any Star
Baker awards.

## Viewership

``` r
viewers_df = read_csv("./hw2_data/viewers.csv") |>
  janitor::clean_names()
```

    ## Rows: 10 Columns: 11
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (11): Episode, Series 1, Series 2, Series 3, Series 4, Series 5, Series ...
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
viewership = 
  viewers_df |>
  pivot_longer(
    cols = series_1:series_10, 
    names_to = "Season",
    values_to = "Values"
  ) |>
  filter(!is.na(episode))
```

### Average Viewrship in Season 1 and Season 5

``` r
avg_view_s1 = 
  viewership |>
  filter(Season == "series_1") |>
  summarize(avg_view_s1 = mean(Values, na.rm = TRUE))

avg_view_s5 = 
  viewership |>
  filter(Season == "series_5") |>
  summarize(avg_view_s5 = mean(Values, na.rm = TRUE))
```

The average viewership in Season 1 was 2.77.

The average viewership in Season 5 was 10.0393.
