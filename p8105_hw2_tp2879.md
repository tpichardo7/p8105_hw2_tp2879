p8105_hw2_tp2879
================

# Problem 1

``` r
nyc_transit_df =  
  read_csv(file = "./hw2_data/nyc_transit.csv",
    col_types = cols(
      Route8 = col_character(), 
      Route9 = col_character(), 
      Route10 = col_character(), 
      Route11 = col_character())) |>
  janitor::clean_names() |>
  pivot_longer(
      cols = route1:route11,
      names_to = "route")
```

``` r
nyc_transit_df |>
  select(
    line, 
    station_location,
    station_name, 
    station_latitude, 
    station_longitude, 
    route, 
    entry, 
    vending, 
    entrance_type, 
    ada
  ) |>
  mutate(entry = ifelse(entry == "YES", TRUE, FALSE))
```

    ## # A tibble: 20,548 × 10
    ##    line   station_location station_name station_latitude station_longitude route
    ##    <chr>  <chr>            <chr>                   <dbl>             <dbl> <chr>
    ##  1 4 Ave… (40.660397, -73… 25th St                  40.7             -74.0 rout…
    ##  2 4 Ave… (40.660397, -73… 25th St                  40.7             -74.0 rout…
    ##  3 4 Ave… (40.660397, -73… 25th St                  40.7             -74.0 rout…
    ##  4 4 Ave… (40.660397, -73… 25th St                  40.7             -74.0 rout…
    ##  5 4 Ave… (40.660397, -73… 25th St                  40.7             -74.0 rout…
    ##  6 4 Ave… (40.660397, -73… 25th St                  40.7             -74.0 rout…
    ##  7 4 Ave… (40.660397, -73… 25th St                  40.7             -74.0 rout…
    ##  8 4 Ave… (40.660397, -73… 25th St                  40.7             -74.0 rout…
    ##  9 4 Ave… (40.660397, -73… 25th St                  40.7             -74.0 rout…
    ## 10 4 Ave… (40.660397, -73… 25th St                  40.7             -74.0 rout…
    ## # ℹ 20,538 more rows
    ## # ℹ 4 more variables: entry <lgl>, vending <chr>, entrance_type <chr>,
    ## #   ada <lgl>

## Number of Distinct Stations

``` r
distinct_stations = nyc_transit_df |>
  distinct(station_name, line) |>
  nrow()
```

## Number of ADA Compliant Stations

``` r
ada_compliant_stations = nyc_transit_df |>
  filter(ada == TRUE) |>
  nrow()
```

## Proportion of Entrances Without Vending that Allow Entry

``` r
total_entrances = nyc_transit_df |>
  filter(vending == "NO") |>
  nrow()

entrances_with_entry = nyc_transit_df |>
  filter(vending == "NO", entry == TRUE) |>
  nrow()

proportion = entrances_with_entry / total_entrances
```

# Problem 2

## Reading and Cleaning the Mr.Trash Wheel sheet

``` r
trash_df = read_xlsx("./hw2_data/trash.xlsx")
```

    ## New names:
    ## • `` -> `...15`
    ## • `` -> `...16`

``` r
trash_df = janitor::clean_names(trash_df)
```

``` r
mr_trash = 
  read_xlsx("./hw2_data/trash.xlsx",
    sheet = "Mr. Trash Wheel",
    skip = 1, 
    col_names = TRUE) |> 
  janitor::clean_names() |> 
  mutate(sports_balls = as.integer(sports_balls)) 
```

    ## New names:
    ## • `` -> `...15`
    ## • `` -> `...16`

## Reading and Cleaning the Professor Trash Wheel sheet

``` r
prof_trash = trash_df = 
  read_xlsx("./hw2_data/trash.xlsx",
    sheet = "Professor Trash Wheel",
    skip = 1, 
    col_names = TRUE) |> 
  janitor::clean_names() 
```

## Reading and Cleaning the Gwynnda Trash Wheel sheet

``` r
g_trash = trash_df = 
  read_xlsx("./hw2_data/trash.xlsx",
    sheet = "Gwynnda Trash Wheel",
    skip = 1, 
    col_names = TRUE) |> 
  janitor::clean_names() 
```

## Combining the Trash Wheel sheets

``` r
major_trash_df = 
  mr_trash |>
  full_join(prof_trash, by = c("dumpster", "month", "weight_tons")) |>
  full_join(g_trash, by = c("dumpster", "month", "weight_tons"))
```

# Problem 3

``` r
bakers_df = 
  read_csv(file = "./hw2_data/bakers.csv", na = c("NA", ".", "")) |>
  janitor::clean_names() |>
  filter(!is.na(baker_name)) |>
  separate(baker_name, into = c("first_name", "last_name"), sep = " ") 
```

    ## Rows: 120 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (3): Baker Name, Baker Occupation, Hometown
    ## dbl (2): Series, Baker Age
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
bakes_df = 
  read_csv(file = "./hw2_data/bakes.csv", na = c("NA", ".", "")) |> 
  janitor::clean_names() |>
  filter(!is.na(baker)) |>
  rename(first_name = baker) 
```

    ## Rows: 548 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (3): Baker, Signature Bake, Show Stopper
    ## dbl (2): Series, Episode
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
results_df = 
  read_csv(file = "./hw2_data/results.csv", na = c("NA", ".", ""), skip = 2) |> 
  janitor::clean_names() |>
  filter(!is.na(baker)) |>
  rename(first_name = baker) 
```

    ## Rows: 1136 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (2): baker, result
    ## dbl (3): series, episode, technical
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
missing_bakers = anti_join(bakes_df, bakers_df, by = "first_name")
missing_results = anti_join(results_df, bakers_df, by = "first_name")
```

## Merging the Datasets

``` r
gbb_df = 
  bakers_df |>
  full_join(bakes_df, by = c("series", "first_name")) |> 
  full_join(results_df, by = c("series","episode", "first_name")) |> 
  arrange(first_name, series, episode) |> 
  relocate(result, series, episode) |> 
  drop_na(result)
```

## Organizing the Combined Dataset

``` r
gbb_df = gbb_df |>
  select(first_name, everything())
```

## Exporting the Final Dataset

``` r
write_csv(gbb_df, "./hw2_data/gbb_final_dataset.csv")
```

## Star Bakers and Winners - Season 5 through Season 10

``` r
star_bakers_df = 
  gbb_df |>
  filter(series >= 5, series <= 10) |>
  filter(result %in% c("STAR BAKER", "WINNER"))|> 
  relocate(first_name, last_name)
```

``` r
bakers_table = 
  star_bakers_df |> 
  select(
    season = series,
    episode = episode,
    star_baker = first_name) |>
  mutate(result = ifelse(star_baker == "Winner", "Winner", "Star Baker")) |> 
  arrange(season, episode)

bakers_table = kable(bakers_table, 
                    caption = "Star Baker or Winner of Each Episode (Seasons 5-10)",
                    format = "markdown",
                    colnames = c("First Name", "Last Name", "Result", "Series", "Episode"))
```

There were a few predictable winners such as Candice Brown of Season 7
who was awarded Star Baker three times before ultimately winning the
Great British Bake Off. There were also a few suprising winners such as
David from Season 10 who won the Great British Bake Off without any Star
Baker awards.

## Viewership

``` r
viewers_df = read_csv("./hw2_data/viewers.csv") |>
  janitor::clean_names()
```

    ## Rows: 10 Columns: 11
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (11): Episode, Series 1, Series 2, Series 3, Series 4, Series 5, Series ...
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
viewership = 
  viewers_df |>
  pivot_longer(
    cols = series_1:series_10, 
    names_to = "Season",
    values_to = "Values"
  ) |>
  filter(!is.na(episode))
```

### Average Viewrship in Season 1 and Season 5

``` r
avg_view_s1 = 
  viewership |>
  filter(Season == "series_1") |>
  summarize(avg_view_s1 = mean(Values, na.rm = TRUE))

avg_view_s5 = 
  viewership |>
  filter(Season == "series_5") |>
  summarize(avg_view_s5 = mean(Values, na.rm = TRUE))
```

The average viewership in Season 1 was 2.77.

The average viewership in Season 5 was 10.0393.
